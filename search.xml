<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>anti-anti-spider concept</title>
      <link href="2021/03/02/anti-anti-spider/"/>
      <url>2021/03/02/anti-anti-spider/</url>
      
        <content type="html"><![CDATA[<h3 id="Anti-Anti-Spider-Concept"><a href="#Anti-Anti-Spider-Concept" class="headerlink" title="Anti-Anti-Spider Concept"></a>Anti-Anti-Spider Concept</h3><blockquote><p>最近因为毕业设计 需要对网络资源进行爬取。记录爬虫的规则与反爬 (网络不是非法之地~</p><p>不做任何盈利目的与网站攻击目的</p></blockquote><h4 id="robots-txt"><a href="#robots-txt" class="headerlink" title="robots.txt"></a>robots.txt</h4><p>每个网站是否可以被爬，以及被爬的范围，都定义在robots.txt。如果一个网站上没有robots.txt，是被认为默许爬虫爬取所有信息。一个自觉且善意的爬虫，应该在抓取网页之前，先阅读robots.txt，了解并执行网站管理者制定的爬虫规则。</p><p>在浏览器输入<code>根域名/robots.txt</code>即可查看爬虫范围。例如<code>https://www.zhihu.com/robots.txt</code>页面：</p><pre class="line-numbers language-none"><code class="language-none">User-agent: Googlebot // 爬虫的名称，若是*，则允许所有爬虫Disallow: /search // 不允许爬虫访问的地址Allow: /search-special //允许爬虫访问的地址Disallow: /*?guide*User-agent: Googlebot-ImageDisallow: /searchAllow: /search-specialDisallow: /*?guide* // regex规则匹配...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h4><ul><li>原理</li></ul><p>本机与服务器之间增加代理服务器，本机通过代理服务器来访问服务器，形成IP伪装</p><ul><li><p>作用</p><ul><li>突破IP限制，访问该IP不能访问的站点</li><li>隐藏真实IP</li></ul></li><li><p>爬虫代理</p></li></ul><p>爬虫在爬取过程中不断更换代理，来更换不同的IP。例如分布式爬虫主要的一个作用就是不同IP代理爬取资源。</p><ul><li>代理分类<ul><li>FTP代理服务器，用来访问FTP服务器</li><li>HTTP代理服务器，用来访问网页</li><li>SSL/TLS代理服务器，用来访问加密网页</li></ul></li></ul><h4 id="反爬技术"><a href="#反爬技术" class="headerlink" title="反爬技术"></a>反爬技术</h4><p>日常上网中遇到的滑动拼图，短信验证码等都属于反爬技术，用来人机验证，阻止爬虫批量爬取网站内容。当然，反爬可能会误伤：导致普通用户无法访问。当网站发现一个IP访问过于频繁，它就会开始反爬策略，要求我们输入验证码或者登陆或直接封ip。</p><p>常见反爬策略：</p><ul><li><p>user-agent识别</p><p>有些爬虫的UA是特殊的，与正常浏览器不一样，可以通过识别UA特征，拒绝该请求。简单来说是终端的环境信息如：Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/533.21.1 (KHTML, like Gecko) Version/5.0.5 Safari/533.21.1。但是这只是一般意义上的ua参数，实际使用中ua代表了一个终端的标识，ID代表了一个用户的标识，随着网络安全的深入，ua已经不再是一串环境的信息字符串，而是开发者单独发开出来的一套甄别终端的算法，成为了单独执行的js文件。一般在requests的headers里面我们都会附带上User_Agent以规避后台检测是否为爬虫的请求，但是随着安全的提升现在的大型网站已经不再用请求头里面的ua，而是使用单独的js本地生成ua参数，再发给浏览器然后对当前的终端进行鉴别。</p></li><li><p>IP访问频率</p><ol><li><p>当IP访问次数超过阀值，则要求登陆或验证码输入。验证码输入错误则禁止请求一段时间，超过一定次数错误则直接封IP。</p></li><li><p>爬虫访问的IP并发都很高，统计IP并发次数来封禁IP</p></li><li><p>IP访问的时间窗口统计来封禁：爬虫爬取网页的频率都是比较固定的，不像人去访问网页，中间的间隔时间比较无规则，所以我们可以给每个IP地址建立一个时间窗口，记录IP地址最近12次访问时间，每记录一次就滑动一次窗口，比较最近访问时间和当前时间，如果间隔时间很长判断不是爬虫，清除时间窗口，如果间隔不长，就回溯计算指定时间段的访问频率，如果访问频率超过阀值，就转向验证码页面让用户填写验证码</p></li><li><p>限制单个IP的访问量：比如10分钟至多允许访问该页面100次</p></li></ol></li><li><p>识别合法爬虫</p><p>一些网站希望被百度，谷歌爬虫爬取。他们会通过识别UA与IP的对应关系(百度/谷歌等爬虫的IP都可以在网络上找到)。</p></li><li><p>蜜罐资源</p><p>爬虫会爬取一些浏览器上访问不到的资源，对访问蜜罐资源的ip统计，进行封禁</p></li><li><p>以特定的参数和密钥生成token，请求需要带上这个token交给服务器验证</p></li><li><p>html，css字体替换。如：机票<code>&lt;span class="kw_01"&gt;</code>元。那么kw_1就需要html渲染后替换成真实的数字。</p></li></ul><p>反反爬策略：</p><ul><li>设置爬取/下载资源延迟，延迟越大越安全</li><li>禁用cookie：一些网站使用cookie识别用户身份，禁用后服务器无法跟踪爬虫轨迹</li><li>变换UA，IP</li><li>浏览器行为模拟：如selenium工具等</li><li>OCR识别，训练深度学习模型识别验证码（比如使用 CNN）或者直接对接打码平台绕过验证码输入；手机验证码接码平台绕过</li><li>分析网页html,js代码，分析出使用的token加密过程，自己构造token去请求api</li></ul><p>爬虫，最困难的部分，也就是反反爬了吧～</p><h4 id="一些算法"><a href="#一些算法" class="headerlink" title="一些算法"></a>一些算法</h4><ul><li><p><strong>BloomFilter</strong></p><p>用于海量URL过滤去重</p></li></ul><h4 id="一些工具"><a href="#一些工具" class="headerlink" title="一些工具"></a>一些工具</h4><ul><li><p>python框架</p><ul><li><p>scrapy：强大爬虫框架，支持分布式与scrapy-redis</p></li><li><p>selenium：可以模拟人类浏览浏览器的动作。使用该工具时会有特殊标示，如webdriver=true，这一点会被反爬</p></li><li><p>faker: 随机user-agent生成库</p></li><li><p>plantomJS：无界面浏览器</p></li></ul></li><li><p>Charles：请求抓包；API分析</p></li><li><p>Chrome：debug调试；API分析</p></li></ul><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p><a href="https://developers.google.com/search/reference/robots_txt?hl=zh-cn">Google Robots.txt规范</a></p><p><a href="https://www.selenium.dev/documentation/zh-cn/getting_started_with_webdriver/">selenium doc</a></p><p><a href="https://www.zhihu.com/question/28168585">知乎-反爬虫策略故事</a></p><p><a href="https://zhuanlan.zhihu.com/p/55187714">知乎-反反爬实践example</a></p><p><a href="https://zhuanlan.zhihu.com/p/55641629">知乎-淘宝反反爬</a></p>]]></content>
      
      
      <categories>
          
          <category> 边城 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spider </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>excellent-blog</title>
      <link href="2021/02/25/excellent-blog/"/>
      <url>2021/02/25/excellent-blog/</url>
      
        <content type="html"><![CDATA[<h3 id="优秀博主"><a href="#优秀博主" class="headerlink" title="优秀博主"></a>优秀博主</h3><blockquote><p>记录一些碰到的优秀blog站点</p></blockquote><ul><li><a href="https://coolshell.cn/featured">陈皓</a>  有思想 有技术 墙裂推荐</li><li><a href="http://www.ruanyifeng.com/blog/">阮一峰</a> 技术与广度</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="2021/02/25/hello-world/"/>
      <url>2021/02/25/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
